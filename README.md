# Efficient-AI-Computing-Resources

## Transformer

**A survey on efficient training of transformers.**<br>
*B Zhuang, J Liu, Z Pan, H He, Y Weng, C Shen.*<br>
arXiv:2302.01107, 2023.
[[Paper](https://arxiv.org/pdf/2302.01107)]

**Full stack optimization of transformer inference: a survey.**<br>
*S Kim, C Hooper, T Wattanawong, M Kang, R Yan, H Genc, G Dinh, Q Huang, K Keutzer, et al.*<br>
arXiv:2302.14017, 2023.
[[Paper](https://arxiv.org/pdf/2302.14017)]

## LLM

**AWQ: Activation-aware Weight Quantization for LLM Compression and Acceleration.**<br>
*Ji Lin, Jiaming Tang, Haotian Tang, Shang Yang, Wei-Ming Chen, Wei-Chen Wang, Guangxuan Xiao, Xingyu Dang, Chuang Gan, Song Han.*<br>
MLSys, 2024.
[[Paper](https://arxiv.org/pdf/2306.00978)]
[[Github](https://github.com/mit-han-lab/llm-awq)]

**QServe: W4A8KV4 Quantization and System Co-design for Efficient LLM Serving.**<br>
*Muyang Li, Tianle Cai, Jiaxin Cao, Qinsheng Zhang, Han Cai, Junjie Bai, Yangqing Jia, Ming-Yu Liu, Kai Li, Song Han.*<br>
ArXiv, 2024.
[[Paper](https://arxiv.org/pdf/2405.04532)]
[[Github](https://hanlab.mit.edu/projects/qserve)]

## VLP

**MobileVLM: A Fast, Strong and Open Vision Language Assistant for Mobile Devices.**<br>
*Xiangxiang Chu, Limeng Qiao, Xinyang Lin, Shuang Xu, et al.*<br>
arXiv, 2023.
[[Paper](https://arxiv.org/pdf/2312.16886v2)]
[[Github](https://github.com/Meituan-AutoML/MobileVLM)]

**MobileVLM V2: Faster and Stronger Baseline for Vision Language Model.**<br>
*X Chu, L Qiao, X Zhang, S Xu, F Wei, Y Yang, et al.*<br>
ArXiv, 2024.
[[Paper](https://arxiv.org/pdf/2402.03766)]
[[Github](https://github.com/Meituan-AutoML/MobileVLM)]

## Diffusion Models

**Snapfusion: Text-to-image diffusion model on mobile devices within two seconds.**<br>
*Y Li, H Wang, Q Jin, J Hu, P Chemerys, Y Fu, Y Wang, S Tulyakov, J Ren.*<br>
Advances in Neural Information Processing Systems, 2024.
[[Paper](https://proceedings.neurips.cc/paper_files/paper/2023/file/41bcc9d3bddd9c90e1f44b29e26d97ff-Paper-Conference.pdf)]
[[Github](https://snap-research.github.io/SnapFusion)]

**DistriFusion: Distributed Parallel Inference for High-Resolution Diffusion Models.**<br>
*Muyang Li, Tianle Cai, Jiaxin Cao, Qinsheng Zhang, Han Cai, Junjie Bai, Yangqing Jia, Ming-Yu Liu, Kai Li, Song Han.*<br>
CVPR, 2024.
[[Paper](https://arxiv.org/pdf/2402.19481)]
[[Github](https://github.com/mit-han-lab/distrifuser)]

## Point Cloud

**Torchsparse: Efficient point cloud inference engine.**<br>
*H Tang, Z Liu, X Li, Y Lin, S Han.*<br>
Proceedings of Machine Learning and Systems, 2022.
[[Paper](https://proceedings.mlsys.org/paper_files/paper/2022/file/c48e820389ae2420c1ad9d5856e1e41c-Paper.pdf)]
[[Github](https://hanlab.mit.edu/projects/torchsparse)]

**Torchsparse++: Efficient training and inference framework for sparse convolution on gpus.**<br>
*H Tang, S Yang, Z Liu, K Hong, Z Yu, X Li, G Dai, Y Wang, S Han.*<br>
MICRO, 2023.
[[Paper](https://dl.acm.org/doi/pdf/10.1145/3613424.3614303)]
[[Github](https://github.com/mit-han-lab/torchsparse)]

## TinyML

### Review

**Tiny Machine Learning: Progress and Futures.**<br>
*J Lin, L Zhu, WM Chen, WC Wang, et al.*<br>
IEEE Circuits and Systems Magazine 23 (3), 8-34, 2023.
[[Paper](https://arxiv.org/pdf/2403.19076)]

### Training

**PockEngine: Sparse and Efficient Fine-tuning in a Pocket.**<br>
*L Zhu, L Hu, J Lin, WM Chen, WC Wang, C Gan, S Han.*<br>
MICRO, 2023.
[[Paper](https://dl.acm.org/doi/pdf/10.1145/3613424.3614307)]

### MCU

**Mcunet: Tiny deep learning on iot devices.**<br>
*J Lin, WM Chen, Y Lin, C Gan, S Han.*<br>
Advances in Neural Information Processing Systems, 2020.
[[Paper](https://proceedings.neurips.cc/paper/2020/file/86c51678350f656dcc7f490a43946ee5-Paper.pdf)]
[[Github](https://hanlab.mit.edu/projects/tinyml)]

**Mcunetv2: Memory-efficient patch-based inference for tiny deep learning.**<br>
*J Lin, WM Chen, H Cai, C Gan, S Han.*<br>
arXiv:2110.15352, 2021.
[[Paper](https://arxiv.org/pdf/2110.15352)]
[[Github](https://hanlab.mit.edu/projects/tinyml)]

**MCUFormer: Deploying Vision Tranformers on Microcontrollers with Limited Memory.**<br>
*Y Liang, Z Wang, X Xu, Y Tang, J Zhou, J Lu.*<br>
Advances in Neural Information Processing Systems, 2024.
[[Paper](https://proceedings.neurips.cc/paper_files/paper/2023/file/1ae4999aefb509d75d8608e07280922c-Paper-Conference.pdf)]
[[Github](https://proceedings.neurips.cc/paper_files/paper/2023/file/1ae4999aefb509d75d8608e07280922c-Paper-Conference.pdf)]
